这是一个介绍性讲座，旨在介绍图像分类问题以及数据驱动方法。目录：

- [Intro to Image Classification, data-driven approach, pipeline](#image-classification)
- Nearest Neighbor Classifier
  - k-Nearest Neighbor
- Validation sets, Cross-validation, hyperparameter tuning
- Pros/Cons of Nearest Neighbor
- Summary
- Summary: Applying kNN in practice
- Further Reading

# Image Classification

**动机 ：**在本节中，我们将介绍图像分类问题，它是从一组固定的类别中为输入图像分配一个标签的任务。这是计算机视觉中的核心问题之一，尽管它很简单，但却有各种各样的实际应用。而且，正如我们在课程后面会看到的，许多其他看似不同的计算机视觉任务（如对象检测，分割）可以简化为图像分类。

**例子 ：**在下面的图像中，图像分类模型将单个图像按照概率分配到4个标签*{猫，狗，帽子，马克杯}*。如图所示，请记住，对于计算机来说，图像被表示为一个大的三维数字数组。在这个例子中，猫的图像宽248像素，高400像素，并且有三个颜色通道红色，绿色，蓝色（简称RGB）。因此，图像由248 x 400 x 3个数字组成，或总共297,600个数字。每个数字是一个整数，范围从0（黑色）到255（白色）。我们的任务是将一百万个数字转换为单个标签，例如*“猫”*。

![](../Images/classify.png)

图像分类的任务是预测给定图像的单个标签（或标签上的分布，如图所示，以表示我们的置信度）。图像是从0到255的整数的三维数组，大小为宽x高x 3 .3代表三个颜色通道红色，绿色和蓝色。

**挑战**。由于识别视觉概念（例如猫）的任务对于人类来说是相对微不足道的，因此从计算机视觉算法的角度考虑所涉及的挑战是值得的。正如我们在下面提出的一个无穷无尽的挑战列表，请记住图像的原始表示形式（为亮度值的三维阵列）：

- **视角变化：**对象的单个实例相对于相机可以以多种角度。
- **比例变化：**视觉类通常表现出尺寸的变化（在现实世界中的大小，不仅仅是图像的大小）。
- **变形：**许多感兴趣的物体不是刚体，可能会以极端方式变形。
- **遮挡：**感兴趣的对象可以被遮挡。有时只有一小部分对象（只有少数像素）可见。
- **光照条件：**照明的影响在像素级上非常剧烈。
- **背景混淆：**感兴趣的对象可以*融合*到他们的环境，使他们很难辨认。
- **类间变化(Intra-class variation)：**感兴趣的对象通常可能比较宽泛的概念，如*椅子*。这些物体有许多不同的类型，每种都有自己的外观。

良好的图像分类模型必须对所有这些变化的交叉乘积保持不变，同时保持对类间变化的敏感性。

![](../Images/challenges.jpeg)

**数据驱动的方法**。我们可以怎样去编写一个可以将图像分类到不同类别的算法？与编写用于对数字列表进行排序的算法不同，很难说如何编写用于识别图像中猫的算法。因此，我们将不会像在孩子身上所采取的那种方式那样，不是直接在代码中指定每种感兴趣的类别，而是要为计算机提供每个类很多示例和迭代的学习算法。同过查看这些例子，学习到每个类的视觉外观。这种方法被称为*数据驱动方法*，因为它依赖于首先累积的*训练数据集*标记图像。下面是一个这样的数据集的例子：

![](../Images/trainset.jpg)

四个视觉类别的示例训练集。实际上，我们可能会为每个类别设置数千个类别和数十万个图像。

**图像分类管道**。我们已经看到，图像分类中的任务是获取代表单个图像的像素阵列并为其分配标签。完整的流程可以形式化如下：

- **输入：**我们的输入由一组*N个*图像组成，每个图像用*K个*不同类别中的一个标记。我们将这些数据称为*训练集*。
- **学习：**我们的任务是使用训练集来了解每个类的外观。我们将这一步称为*训练分类器*，或者*学习模型*。
- **评估：**最后，我们评估分类器的质量，通过要求它为一组以前从未见过的新图像预测标签。然后，我们将比较这些图像的真实标签与分类器预测的标签。直觉上，我们希望很多预测与真实答案（我们称之为*基本事实*）相匹配。